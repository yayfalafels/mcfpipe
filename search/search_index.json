{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MCF Pipe","text":"<p>Your automated assistant for Singapore\u2019s job market.</p>"},{"location":"#links","title":"Links","text":"<ul> <li>documentation: MCFPipe</li> <li>MyCareerFutures (MCF) website</li> </ul>"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/#system-architecture","title":"System architecture","text":"<p>There are several components of the app, broadly grouped into storage and compute</p> <p>Storage</p> id component description current AWS Infra 01 job posts data jobs and job posts local SQLite database DynamoDB 02 dimension tables config, tracks, keyword libraries GSheet tables DynamoDB 03 CRM data screened, applied, closed, responses, track assignment GSheet tables DynamoDB 04 jobs applied status jobs applied status from MCF apply Gsheet table DynamoDB 05 reports jobs by stage CRM performance analysis Gsheet table SQLite on S3 <p>Compute</p> id component description current AWS Infra 01 Webscraper get MCF search results and job post pages local python scripts Fargate container 02 HTML Parser HTML parse and write to DB local python scripts Lambda + SQS 03 Job Recommender score the posts local python scripts Fargate container 04 GSheet Connector GSheet UI interface local python scripts Lambda 05 MCF Login refresh session cookie manual S3 + Lambda 06 MCF Apply apply jobs local python scripts container Fargate + ECR 07 CRM API write-back, status updates, select jobs to apply, config update GSheet CRM API on EC2 08 Analytics ETL Denormalize from DynamoDB to Parquet GSheet Lambda, Glue, Athena 09 Dashboard Reports and data visualization GSheet PowerBI connect to SQLite on S3 10 DynamoDB API DynamoDB interface API - API Gateway + Lambda 11 Network VPC and network infrastructure - Networking"},{"location":"architecture/#aws-infrastructure","title":"AWS Infrastructure","text":"<p>The AWS infrastructure is organized into layered CloudFormation stacks, segregated by function and coupled through the repository via parameters and configuration files.</p> <p>Cloudformation stacks Cloudformation stack layers</p> id stack purpose resources 01 networking network and VPC for public and private subnets VPC, subnets, security groups, internet gateway 02 database storage database and connector API DynamoDB tables 03 webscraper serverless Fargate compute resource for Webscraper Fargate compute tasks <p>AWS CLI Additional resources created outside of the cloudformation stack either manually from local PC or via Github actions. </p> <p>These resources must be deleted in a separate cleanup workflow.</p> <p>manual setup resources</p> id resource executor sequence 01 S3 bucket Github Action initial setup 02 S3 config Github Action initial setup after s3 bucket creation 03 ECR Dockerimage Github Action before Webscraper stack deploy"},{"location":"architecture/#network","title":"Network","text":"<p>Network access control requirements for AWS-based components in the application architecture. </p> <ul> <li>All public subnets must be associated with an Internet Gateway.</li> <li>VPC endpoints are required for private subnets that need to reach the internet</li> <li>Security groups should be tightly scoped to match access intent (SSH only, HTTP only, etc.).</li> <li>Where possible, use least privilege IAM roles and environment-specific configuration.</li> </ul> <p>Access Groups</p> id access group access control resources 01 global AWS managed IAM credentials S3, Athena, Glue Catalog 02 private subnet VPC + IAM Lambda ETL, DB API, Glue jobs 03 public subnet: outbound only + SSH IAM + SSH key, no inbound HTTP allowed Webscraper, Sheets UI, test EC2 04 public subnet: inbound/outbound HTTP IAM + app-level authentication CRM API (e.g., Flask on EC2/ALB/Fargate)"},{"location":"architecture/#database-api","title":"Database API","text":"<p>The Database API is a single interface point to the backend DynamoDB database</p>"},{"location":"architecture/#webscraper-container","title":"Webscraper container","text":"<p>The webscraper runs on a Fargate container and runs the following tasks. The scope of the webscraper is interface with the MCF website using selenium webdriver. The webscraper uses the python library <code>mcfscrape</code>.</p> <p>Base image Base image: <code>python:3.11-slim</code></p> <p>Requirements</p> <p>docker environment</p> <ul> <li>apt-get update (standard)</li> <li>ca-certificates</li> <li>chromium chromium-driver</li> </ul> <p>python dependencies</p> <ul> <li>selenium &gt;= 4.6</li> <li>boto3</li> <li>BeautifulSoup (bs4)</li> <li>requests (optional)</li> </ul> <p>Tasks</p> <p>Tasks include either</p> <ol> <li>POST to apply for selected jobs</li> <li>GET content and save into raw HTML source code files for downstream processing.</li> </ol> id task description 01 keyword search search by keyword and paginate search results to html files by page 02 job pages fetch fetch job post page save to html file 03 jobs apply use stored session cookie from S3, submit job application from job toapply config and navigate through apply pages"},{"location":"cicd/","title":"CICD","text":"<p>Deployment from source code</p>"},{"location":"cicd/#cicd-resources","title":"CICD resources","text":"<ul> <li>Github repository: mcfpipe source code storage</li> <li>Github Actions: deployment engine</li> <li>AWS CloudFormation: IaC templates for managing cloud infrastructure on AWS</li> </ul>"},{"location":"cicd/#repository-layout","title":"repository layout","text":"<p>the repository files are organized in the following structure</p> <p>/root <pre><code>.github/\n  workflows/            # github deploy actions\n     ...\naws/                    # cloudformation templates and specifications for AWS infrastructure\n  dynamodb/\n    ...\n  ecr/\n    ...\n  fargate/\n    ...\n  lambda/\n    ...\n  s3/\n    ...\ncompute/                # source code and config for compute resources\n  webscraper/\n    ...\ndev/\n  releases/             # documentation for each release\n    ...\ndocs/                   # app documentation\n  ...\njobsearch/              # legacy app source code\n  ...\ngsheetui/               # Gsheet connector using Google Sheets API\n  gsheet/\n    __init__.py\n    ...\n  gsheet_schema.json\n  api_config.json\n  requirements.txt\nmcfparse/              # HTML Parser python module source code\n  mcfparse/\n    __init__.py\n    parser.py\n    ...\n  requirements.txt\nmcfscrape/              # Webscraper python module source code\n  mcfscrape/\n    __init__.py\n    webscraper.py\n    ...\n  requirements.txt\njobcrm/                 # CRM Backend API\n  app/\n    __init__.py\n  requirements.txt\n  ...\njobdb/                   # Database API\n  db/\n    __init__.py\n  requirements.txt\njobmatch/                 # Job recommendation python module\n  jobmatch/\n    __init__.py\n  requirements.txt\n  ...\njobpipe/                 # Analytics ETL python module\n  jobpipe/\n    __init__.py\n  requirements.txt\n  ...\nstorage/                # schema and config for storage resources\n  search_profile/\n    ...\n  jobs/\n    ...  \n.gitignore\nAGENTS.md               # instructions for Developer AI assistants\nLICENSE\nmkdocs.yml\nrequirements.txt\nVERSION\n</code></pre></p> <p>excluded files and directories excluded from the source code from <code>.gitignore</code></p> <p>.gitignore <pre><code>env\nsite\n.env\n</code></pre></p>"},{"location":"cicd/#s3-bucket-layout","title":"S3 bucket layout","text":"<p>S3 bucket: <code>mcfpipe</code> <pre><code>apps/                     # source code for apps\nconfig/                   # setup infrastructure and app configuration\naws/                      # information for the AWS infrastructure\n  network/\n    network_config.json\n  ecr/\n    containers.json\nstorage/\n  db_api.json             # endpoint access for database API\n  db_schema.json\nuser_data/                # user-specific settings and configuration data\n  user_#####/\n    ...\n</code></pre></p>"},{"location":"data_model/","title":"Data model","text":"<p>data model with list of tables and schema information</p> <p>Groups</p> id group description 01 user users and settings 02 search role, role-specific tracks and search profile 03 job job information with workflow status and details scraped from posts and user-updated <p>Tables</p> id group table description 01 jobs job list of registered jobs, includes url and workflow status codes 02 jobs post_details job details either scraped from post or manually updated 03 user user list of users 04 user user_config user profile and customization settings 05 search role generic job roles ex Data Engineer, Data Scientist 06 search track strategic tracks user-role pairs with additional specification for seniority 07 search search_profile search configuration by track: keywords, target salary"},{"location":"data_model/#jobs","title":"Jobs","text":"<p>data tables to describe job information scraped from job post</p> <p>ERD</p> <pre><code>erDiagram\n    job {\n        String id PK\n        String posted_date\n        String position\n        String company_name\n        String url\n        String card_position\n        String card_company_name\n        Number load_status\n        Number crm_status\n        Number apply_status\n    }\n\n    post_details {\n        String jobid PK, FK\n        String closing_date\n        Number salary_high_sgd\n        String mcf_ref\n    }\n\n    job ||--o{ post_details : has</code></pre>"},{"location":"data_model/#table-job","title":"Table: job","text":"<ul> <li>Primary Key: <code>id</code> </li> <li>Sort Key: <code>posted_date</code></li> </ul> Column Name Data Type Nullable Description id String No Unique job identifier posted_date String No Date the job was posted position String No Job title company_name String Yes Full company name url String Yes URL to the job post card_position String Yes Position title from card preview card_company_name String Yes Company name from card preview load_status Number No Ingestion stage (e.g., 0=CARD, 1=POST) crm_status Number Yes CRM funnel stage (e.g., SHORTLIST, etc.) apply_status Number Yes Application outcome (e.g., TOAPPLY)"},{"location":"data_model/#table-post_details","title":"Table: post_details","text":"<ul> <li>Primary Key: <code>jobid</code></li> <li>Sort Key: <code>closing_date</code></li> </ul> Column Name Data Type Nullable Description jobid String No Foreign key to job table closing_date String No Application deadline date salary_high_sgd Number Yes Maximum salary in SGD mcf_ref String Yes MCF reference code"},{"location":"data_model/#users","title":"Users","text":"<p>user-related configuration tables</p> <p>ERD</p> <pre><code>erDiagram\n    user {\n        String id PK\n        String email\n        String username\n        String name\n        String created_date\n        String deactivated_date\n        Number status\n    }\n\n    user_config {\n        String userid PK, FK\n        Boolean email_notifications\n    }\n\n    user ||--o{ user_config : has</code></pre>"},{"location":"data_model/#table-user","title":"Table: user","text":"<ul> <li>Primary Key: <code>id</code></li> </ul> Column Name Data Type Nullable Description id String No Unique user identifier email String No Email address username String No Username name String Yes Full name created_date String No Account creation date deactivated_date String Yes Account deactivation date status Number No User status (e.g., 1=active)"},{"location":"data_model/#table-user_config","title":"Table: user_config","text":"<ul> <li>Primary Key: <code>userid</code></li> </ul> Column Name Data Type Nullable Description userid String No Foreign key to user email_notifications Boolean Yes Whether user receives email notifications"},{"location":"data_model/#search","title":"Search","text":"<p>tables related to search configuration</p> <p>ERD</p> <pre><code>erDiagram\n    user {\n        String id PK\n    }\n\n    role {\n        String id PK\n        String role_name\n        String description\n    }\n\n    track {\n        String id PK\n        String userid FK\n        String roleid FK\n        Number seniority\n    }\n\n    search_profile {\n        String trackid PK, FK\n        String keywords\n        Number salary_target_sgd\n    }\n\n    user ||--o{ track : has\n    role ||--o{ track : has\n    track ||--o{ search_profile : has</code></pre>"},{"location":"data_model/#table-role","title":"Table: role","text":"<ul> <li>Primary Key: <code>id</code></li> </ul> Column Name Data Type Nullable Description id String No Role identifier role_name String No Name of the role description String Yes Description of role"},{"location":"data_model/#table-track","title":"Table: track","text":"<ul> <li>Primary Key: <code>id</code></li> <li>Sort Key: <code>userid</code></li> </ul> Column Name Data Type Nullable Description id String No Track identifier userid String No Foreign key to user roleid String No Foreign key to role seniority Number Yes Level of seniority (e.g., 1)"},{"location":"data_model/#table-search_profile","title":"Table: search_profile","text":"<ul> <li>Primary Key: <code>trackid</code></li> </ul> Column Name Data Type Nullable Description trackid String No profile ID and foreign key to track keywords String Yes Keywords for job search salary_target_sgd Number Yes Target salary in SGD"},{"location":"database_api/","title":"Database API","text":"<p>The <code>Database API</code> provides a RESTful interface for CRUD operations on DynamoDB tables defined in the system data model. The API is implemented as a generic Lambda function behind API Gateway, supporting dynamic routing based on path parameters and validating requests using the canonical schema file <code>db_schema.json</code>.</p> <p>This service is designed to act as a thin, schema-aware wrapper over the DynamoDB backend to enable flexible, centralized, and secure access to all operational data in the jobsearch system.</p>"},{"location":"database_api/#design-principles","title":"Design Principles","text":"<ul> <li>Generic Routing: Dynamic table access via path parameters.</li> <li>Schema Enforcement: All incoming payloads are validated against <code>db_schema.json</code>.</li> <li>Minimal Endpoints: A small set of HTTP routes supports all CRUD and batch operations.</li> <li>Modular: Tables can be added/updated without code changes.</li> <li>Internal Use: This API is intended for trusted internal services (e.g., ingestion, screening, CRM).</li> </ul>"},{"location":"database_api/#route-definitions","title":"Route Definitions","text":"<p>Single Record Operations</p> Method Path Description GET <code>/[table]/{id}</code> Fetch item by primary key PUT <code>/[table]/{id}</code> Replace existing item DELETE <code>/[table]/{id}</code> Delete item by primary key <p>Bulk Operations</p> Method Path Description POST <code>/[table]</code> Create a new item POST <code>/[table]/batch</code> Create or update multiple items GET <code>/[table]/search</code> Query items using secondary keys POST <code>/[table]/delete</code> Delete multiple items (by key list)"},{"location":"database_api/#path-parameters","title":"Path Parameters","text":"Param Type Description <code>table</code> string Target table name from schema <code>id</code> string Primary key value"},{"location":"database_api/#body-format","title":"Body Format","text":""},{"location":"database_api/#post-table","title":"POST /[table]","text":"<p>sample body for POST <code>/{job}</code> request</p> <p>request <pre><code>{\n  \"posted_date\": \"2025-08-01\",\n  \"position\": \"Data Engineer\",\n  \"url\": \"https://example.com/jobs/abc123\",\n  ...\n}\n</code></pre></p> <p>response body <pre><code>{\n    \"status\": 1,\n    \"ids\": [\"abc123\"]\n}\n</code></pre></p>"},{"location":"enhancements/","title":"Enhancements","text":"<p>Enhancement categories</p> <ul> <li>Cloud and Infrastructure</li> <li>Database and Backend</li> <li>Data Model and ETL</li> <li>Application Logic </li> <li>Match Scoring &amp; Intelligence</li> <li>UI &amp; Front-End</li> </ul>"},{"location":"enhancements/#status","title":"Status","text":"id status enhancement category release 01 open Migrate to AWS using CloudFormation Cloud and Infrastructure 0.1.0 02 open CICD pipeline setup Cloud and Infrastructure 0.1.0 03 backlog Modularize front-end and back-end with API support for agent integration Cloud and Infrastructure 04 backlog Migrate from SQLite to DynamoDB Database and Backend 05 open Implement batching with intermediate DB writes (currently all-or-nothing) Database and Backend 0.1.0 06 backlog Add async support to reduce script latency (cards: 15 min, profiles: 3\u20135 min) Database and Backend 07 backlog Expand data model to include front-end operational tables (currently in Google Sheets) Data Model and ETL 08 backlog Build ETL pipeline to feed into PowerBI dashboard Data Model and ETL 09 backlog Combine cards and profiles components Application Logic 10 backlog Streamline manual lead addition Application Logic 11 backlog Automate track assignment Application Logic 12 backlog Improve SingPass MFA session cookie handling Application Logic 13 backlog Move beyond keyword-only title matching Match Scoring and Intelligence 14 backlog Incorporate job description Match Scoring and Intelligence 15 backlog Use BERT or other ML models Match Scoring and Intelligence 16 backlog Migrate from Google Sheets UI to React.js or Django app UI and Front End 17 backlog Optionally keep GS integration for tabular views UI and Front End"},{"location":"network/","title":"Network","text":"<p>Network access control requirements for AWS-based components in the application architecture. </p> <ul> <li>All public subnets must be associated with an Internet Gateway.</li> <li>VPC endpoints are required for private subnets that need to reach the internet</li> <li>Security groups should be tightly scoped to match access intent (SSH only, HTTP only, etc.).</li> <li>Where possible, use least privilege IAM roles and environment-specific configuration.</li> </ul> <p>Access Groups</p> id access group access control resources 01 global AWS managed IAM credentials S3, Athena, Glue Catalog 02 private subnet VPC + IAM Lambda ETL, DB API, Glue jobs 03 public subnet: outbound only + SSH IAM + SSH key, no inbound HTTP allowed Webscraper, Sheets UI, test EC2 04 public subnet: inbound/outbound HTTP IAM + app-level authentication CRM API (e.g., Flask on EC2/ALB/Fargate)"},{"location":"network/#01-global-aws-managed-services","title":"01. Global AWS Managed Services","text":"<ul> <li>These services are accessed over the public AWS network.</li> <li>No subnet or VPC routing is required.</li> <li>Access is controlled entirely via IAM permissions.</li> </ul> <p>Includes:</p> <ul> <li>S3 (data lake, Parquet storage)</li> <li>Athena (SQL query interface)</li> <li>Glue Catalog (metadata management)</li> </ul>"},{"location":"network/#02-private-subnet-vpc-only","title":"02. Private Subnet (VPC-Only)","text":"<ul> <li>Resources are not publicly accessible.</li> <li>Outbound access is granted via VPC endpoints.</li> <li>Designed for secure backend tasks and services.</li> </ul> <p>Includes:</p> <ul> <li>Lambda ETL functions</li> <li>Glue transformation jobs</li> <li>Internal-facing Database API</li> </ul>"},{"location":"network/#03-public-subnet-outbound-ssh","title":"03. Public Subnet: Outbound + SSH","text":"<ul> <li>Public subnet with internet access for outbound requests.</li> <li>Allows SSH inbound, but blocks HTTP traffic (ports 80/443).</li> <li>Public IPs are assigned automatically (Fargate or EC2).</li> <li>Useful for browser automation, debugging, or interactive tools.</li> </ul> <p>Includes: - Webscraper (e.g., Selenium headless on Fargate) - Google Sheets UI connector - Temporary EC2 debug instances</p>"},{"location":"network/#04-public-subnet-inboundoutbound-http","title":"04. Public Subnet: Inbound/Outbound HTTP","text":"<ul> <li>Public-facing APIs with full internet access.</li> <li>Allows inbound HTTP/S via security group.</li> <li>Should include authentication to protect API endpoints.</li> <li>Can be hosted on EC2, Fargate, or fronted with ALB.</li> </ul> <p>Includes: - CRM API (Flask or Django) - Optional: ALB if scaling to multiple instances</p>"},{"location":"workflows/","title":"Workflows","text":"<p>App workflows</p> id workflow description 01 jobs search scrape data from MCF website parse and store into database 02 jobs recommend score and screen jobs for curated report jobs to apply 03 jobs apply apply jobs through MCF website from shortlisted jobs to apply 04 CRM API CRUD operational actions to manage search and move leads through pipeline 05 analytics ETL update parquet DB from data sources DynamoDB tables and refresh BI report 06 config sync update config settings"},{"location":"workflows/#jobs-search","title":"Jobs search","text":"<pre><code>graph TB\n\n%% Config\nDynamoConfig[\"Dynamo: Search config\"]\n\n%% Extraction phase\nCardScraper[\"Fargate: Card Scraper\"]\nS3Cards[\"S3: Card HTML\"]\nCardsQueue[\"SQS: Cards Queue\"]\nParser1[\"Lambda: HTML Parser (cards)\"]\nJobsDB[\"DynamoDB: Jobs\"]\n\nPostScraper[\"Fargate: Post Scraper\"]\nS3Posts[\"S3: Full Post HTML\"]\nPostsQueue[\"SQS: Post Queue\"]\nParser2[\"Lambda: HTML Parser (posts)\"]\n\n%% Transformation + Enrichment\nScorer[\"Lambda: Job Scorer\"]\n\n%% Flow\nDynamoConfig --&gt; CardScraper\nCardScraper --&gt; S3Cards\nCardScraper --&gt; CardsQueue\nCardsQueue --&gt; Parser1\nS3Cards --&gt; Parser1\nParser1 --&gt; CardsQueue\nParser1 --&gt; JobsDB\nCardsQueue --&gt; PostScraper\n\nJobsDB --&gt; PostScraper\nPostScraper --&gt; S3Posts\nPostScraper --&gt; PostsQueue\nPostsQueue --&gt; Parser2\nParser2 --&gt; PostsQueue\nS3Posts --&gt; Parser2\nParser2 --&gt; JobsDB\nPostsQueue --&gt; Scorer\n</code></pre>"},{"location":"workflows/#jobs-recommend","title":"Jobs recommend","text":"<pre><code>graph TB\n\n%% Config\nDynamoConfig[\"Dynamo: Search config\"]\n\n%% Transformation + Enrichment\nJobsDB[\"DynamoDB: Jobs\"]\nPostsQueue[\"SQS: Post Queue\"]\nScorer[\"Lambda: Job Scorer\"]\nScores[\"DynamoDB: Job Scores\"]\n\n%% Decisioning\nScreener[\"Lambda: Screener\"]\nCRM[\"DynamoDB: CRM Data (screened)\"]\n\n%% Flow\nPostsQueue --&gt; Scorer\nDynamoConfig --&gt; Scorer\nJobsDB --&gt; Scorer\nScorer --&gt; Scores\n\nScores --&gt; Screener\nJobsDB --&gt; Screener\nScreener --&gt; CRM\n</code></pre>"},{"location":"workflows/#jobs-apply","title":"Jobs apply","text":"<pre><code>graph TB\n\n%% Cookies\nCredRefresh[\"laptop: login MFA cookie refresh\"]\nCookie[\"DynamoDB: User config (MCF session cookie)\"]\n\n%% Jobs Apply\nUser[\"User\"]\nJobsApply[\"Fargate: MCF jobs apply\"]\nToApply[\"DynamoDB: CRM Data (jobs to apply)\"]\n\n%% Flow\nUser --&gt; CredRefresh\nUser --&gt; JobsApply\nCredRefresh --&gt; Cookie\nCookie --&gt; JobsApply\nToApply --&gt; JobsApply\nJobsApply --&gt; ToApply\n</code></pre>"},{"location":"workflows/#crm-api","title":"CRM API","text":"<pre><code>graph RL\n\nFEApp[\"EC2 Front-end App\"]\nLegacyGSheet[\"Legacy Gsheet UI\"]\nGsheetSync[\"Lambda Gsheet API interface\"]\nCRMAPI[\"CRM API\"]\n\n%% CRM API\nFEApp --&gt; CRMAPI\nCRMAPI --&gt; FEApp \nGsheetSync --&gt; CRMAPI\nGsheetSync --&gt; LegacyGSheet\nLegacyGSheet --&gt; GsheetSync\nCRMAPI --&gt; GsheetSync\n</code></pre>"},{"location":"workflows/#analytics-etl","title":"Analytics ETL","text":"<pre><code>graph TB\n\nDBAPI[\"Database API\"]\nLambdaETL[\"Lambda ETL to Parquet\"]\nDB[\"Parquet DB in S3\"]\nGlue[\"AWS Glue Catalog\"]\nAthena[\"Athena SQL connector\"]\nDF[\"Azure Data Factory\"]\nSSQL[\"Synapse Serverless SQL\"]\nPBI[\"PowerBI\"]\nTBI[\"Tableau\"]\n\n%% ETL flow\nDBAPI --&gt; LambdaETL\nLambdaETL --&gt; DB\nDB --&gt; Glue\nGlue --&gt; Athena\nAthena --&gt; TBI\nDB --&gt; DF\nDF --&gt; SSQL\nSSQL --&gt; PBI\n</code></pre>"},{"location":"releases/010_cloud_infra/","title":"Cloud Infrastructure","text":"<p>This release covers the setup of Cloud infrastructure on AWS for the MCF pipe serverless backend API and database</p>"},{"location":"releases/010_cloud_infra/#situation","title":"Situation","text":"<p>The current version of the app <code>jobsearch</code> runs locally on PC.  Migrating to the cloud improves maintainability and pathway for full automation, with some drawback in development and small cloud operating costs.</p>"},{"location":"releases/010_cloud_infra/#objectives-and-aims","title":"Objectives and aims","text":"<p>Migrate current functionality to AWS Cloud. </p>"},{"location":"releases/010_cloud_infra/#scope","title":"Scope","text":"<p>The current scope includes </p> <ul> <li>Network infrastructure</li> <li>DynamoDB database API</li> <li><code>jobs search</code> workflow</li> </ul> <p>Jobs search Scrape data from MCF website parse and store into cloud AWS DynamoDB database</p>"},{"location":"releases/010_cloud_infra/#system-architecture","title":"System architecture","text":"<p>There are several components of the app, broadly grouped into storage and compute</p> <p>Storage</p> id component description current AWS Infra 01 job posts data jobs and job posts local SQLite database DynamoDB 02 dimension tables config, tracks, keyword libraries GSheet tables DynamoDB 03 CRM data screened, applied, closed, responses, track assignment GSheet tables DynamoDB 04 jobs applied status jobs applied status from MCF apply Gsheet table DynamoDB 05 reports jobs by stage CRM performance analysis Gsheet table SQLite on S3 <p>Compute</p> id component description current AWS Infra 01 Webscraper get MCF search results and job post pages local python scripts Fargate container 02 HTML Parser HTML parse and write to DB local python scripts Lambda + SQS 03 Job Recommender score the posts local python scripts Fargate container 04 GSheet Connector GSheet UI interface local python scripts Lambda 05 MCF Login refresh session cookie manual S3 + Lambda 06 MCF Apply apply jobs local python scripts container Fargate + ECR 07 CRM API write-back, status updates, select jobs to apply, config update GSheet CRM API on EC2 08 Analytics ETL Denormalize from DynamoDB to Parquet GSheet Lambda, Glue, Athena 09 Dashboard Reports and data visualization GSheet PowerBI connect to SQLite on S3 10 DynamoDB API DynamoDB interface API - API Gateway + Lambda 11 Network VPC and network infrastructure - Networking"},{"location":"releases/010_cloud_infra/#app-libraries","title":"App libraries","text":"<p>The source code is modularlized into app libraries since they have unique dependency and environment requirements</p> component requirements resource app library Webscraper selenium, boto3, bs4 Fargate container mcfscrape HTML Parser boto3, bs4 Lambda mcfparse Job Recommender pandas, nltk, scikit-learn, openai Fargate container jobmatch CRM API TBD Flask/Django API Gateway + Lambda jobcrm Analytics ETL pandas, boto3, sqlite3 Lambda jobpipe Gsheet Connector pandas, google api, boto3 Lambda gsheetui Database API boto3 API Gateway + Lambda jobdb"}]}