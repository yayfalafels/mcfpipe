{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MCF Pipe","text":"<p>Your automated assistant for Singapore\u2019s job market.</p>"},{"location":"#links","title":"Links","text":"<ul> <li>documentation: MCFPipe</li> <li>MyCareerFutures (MCF) website</li> </ul>"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/#system-architecture","title":"System architecture","text":"<p>There are several components of the app, broadly grouped into storage and compute</p> <p>Storage</p> id component description current AWS Infra 01 job posts data jobs and job posts local SQLite database DynamoDB 02 dimension tables config, tracks, keyword libraries GSheet tables DynamoDB 03 CRM data screened, applied, closed, responses, track assignment GSheet tables DynamoDB 04 jobs applied status jobs applied status from MCF apply Gsheet table DynamoDB 05 reports jobs by stage CRM performance analysis Gsheet table SQLite on S3 <p>Compute</p> id component description current AWS Infra 01 Webscraper get MCF search results and job post pages local python scripts Fargate container 02 HTML Parser HTML parse and write to DB local python scripts Lambda + SQS 03 Job Recommender score the posts local python scripts Fargate container 04 GSheet Connector GSheet UI interface local python scripts Lambda 05 MCF Login refresh session cookie manual S3 + Lambda 06 MCF Apply apply jobs local python scripts container Fargate + ECR 07 CRM API write-back, status updates, select jobs to apply, config update GSheet CRM API on EC2 08 Analytics ETL Denormalize from DynamoDB to Parquet GSheet Lambda, Glue, Athena 09 Dashboard Reports and data visualization GSheet PowerBI connect to SQLite on S3 10 DynamoDB API DynamoDB interface API - API Gateway + Lambda 11 Network VPC and network infrastructure - Networking"},{"location":"architecture/#aws-infrastructure","title":"AWS Infrastructure","text":"<p>The AWS infrastructure is organized into layered CloudFormation stacks, segregated by function and coupled through the repository via parameters and configuration files.</p> <p>Cloudformation stacks Cloudformation stack layers</p> id stack purpose resources 01 networking network and VPC for public and private subnets VPC, subnets, security groups, internet gateway 02 database storage database and connector API DynamoDB tables 03 webscraper serverless Fargate compute resource for Webscraper Fargate compute tasks <p>AWS CLI Additional resources created outside of the cloudformation stack either manually from local PC or via Github actions. </p> <p>These resources must be deleted in a separate cleanup workflow.</p> <p>manual setup resources</p> id resource executor sequence 01 S3 bucket Github Action initial setup 02 S3 config Github Action initial setup after s3 bucket creation 03 ECR Dockerimage Github Action before Webscraper stack deploy"},{"location":"architecture/#network","title":"Network","text":"<p>Network access control requirements for AWS-based components in the application architecture. </p> <ul> <li>All public subnets must be associated with an Internet Gateway.</li> <li>VPC endpoints are required for private subnets that need to reach the internet</li> <li>Security groups should be tightly scoped to match access intent (SSH only, HTTP only, etc.).</li> <li>Where possible, use least privilege IAM roles and environment-specific configuration.</li> </ul> <p>Access Groups</p> id access group access control resources 01 global AWS managed IAM credentials S3, Athena, Glue Catalog 02 private subnet VPC + IAM Lambda ETL, DB API, Glue jobs 03 public subnet: outbound only + SSH IAM + SSH key, no inbound HTTP allowed Webscraper, Sheets UI, test EC2 04 public subnet: inbound/outbound HTTP IAM + app-level authentication CRM API (e.g., Flask on EC2/ALB/Fargate)"},{"location":"architecture/#database-api","title":"Database API","text":"<p>The Database API is a single interface point to the backend DynamoDB database</p>"},{"location":"architecture/#webscraper-container","title":"Webscraper container","text":"<p>The webscraper runs on a Fargate container and runs the following tasks. The scope of the webscraper is interface with the MCF website using selenium webdriver. The webscraper uses the python library <code>mcfscrape</code>.</p> <p>Base image Base image: <code>python:3.11-slim</code></p> <p>Requirements</p> <p>docker environment</p> <ul> <li>apt-get update (standard)</li> <li>ca-certificates</li> <li>chromium chromium-driver</li> </ul> <p>python dependencies</p> <ul> <li>selenium &gt;= 4.6</li> <li>boto3</li> <li>BeautifulSoup (bs4)</li> <li>requests (optional)</li> </ul> <p>Tasks</p> <p>Tasks include either</p> <ol> <li>POST to apply for selected jobs</li> <li>GET content and save into raw HTML source code files for downstream processing.</li> </ol> id task description 01 keyword search search by keyword and paginate search results to html files by page 02 job pages fetch fetch job post page save to html file 03 jobs apply use stored session cookie from S3, submit job application from job toapply config and navigate through apply pages"},{"location":"cicd/","title":"CICD","text":"<p>Deployment from source code</p>"},{"location":"cicd/#cicd-resources","title":"CICD resources","text":"<ul> <li>Github repository: mcfpipe source code storage</li> <li>Github Actions: deployment engine</li> <li>AWS CloudFormation: IaC templates for managing cloud infrastructure on AWS</li> <li>Tester App: Tester module runs on a dedicated Fargate container in the public subnet</li> </ul>"},{"location":"cicd/#repository-layout","title":"repository layout","text":"<p>the repository files are organized in the following structure</p> <p>/root <pre><code>.github/\n  workflows/            # github deploy actions\n     ...\naws/                    # cloudformation templates and specifications for AWS infrastructure\n  dynamodb/\n    ...\n  ecr/\n    ...\n  fargate/\n    ...\n  lambda/\n    ...\n  s3/\n    ...\ncompute/                # source code and config for compute resources\n  webscraper/\n    ...\ndev/\n  releases/             # documentation for each release\n    ...\ndocs/                   # app documentation\n  ...\njobsearch/              # legacy app source code\n  ...\ngsheetui/               # Gsheet connector using Google Sheets API\n  gsheet/\n    __init__.py\n    ...\n  gsheet_schema.json\n  api_config.json\n  requirements.txt\nmcfparse/              # HTML Parser python module source code\n  mcfparse/\n    __init__.py\n    parser.py\n    ...\n  requirements.txt\nmcfscrape/              # Webscraper python module source code\n  mcfscrape/\n    __init__.py\n    webscraper.py\n    ...\n  requirements.txt\njobcrm/                 # CRM Backend API\n  app/\n    __init__.py\n  requirements.txt\n  ...\njobdb/                   # Database API\n  db/\n    __init__.py\n  requirements.txt\njobmatch/                 # Job recommendation python module\n  jobmatch/\n    __init__.py\n  requirements.txt\n  ...\njobpipe/                 # Analytics ETL python module\n  jobpipe/\n    __init__.py\n  requirements.txt\n  ...\nsetup/                  # Initial setup and global configuration\n  config.env            # global env variables ex: S3_BUCKET \nstorage/                # schema and config for storage resources\n  search_profile/\n    ...\n  jobs/\n    ...  \ntester/                # Tester app that runs on Fargate container\n  tester/\n    __init__.py\n  tests.py\n  requirements.txt\n.gitignore\nAGENTS.md               # instructions for Developer AI assistants\nLICENSE\nmkdocs.yml\nrequirements.txt\nVERSION\n</code></pre></p> <p>excluded files and directories excluded from the source code from <code>.gitignore</code></p> <p>.gitignore <pre><code>env\nsite\n.env\n*client_secret.json\n.pytest_cache*\ns3-mcfpipe*           # local copy of the contents of the S3 directory\n</code></pre></p>"},{"location":"cicd/#s3-bucket-layout","title":"S3 bucket layout","text":"<p>S3 bucket: <code>mcfpipe</code> <pre><code>apps/                     # source code for apps\nconfig/                   # setup infrastructure and app configuration\naws/                      # information for the AWS infrastructure\n  network/\n    network_config.json\n  ecr/\n    containers.json\nstorage/\n  db_api.json             # endpoint access for database API\n  db_schema.json\nuser_data/                # user-specific settings and configuration data\n  user_#####/\n    ...\n</code></pre></p>"},{"location":"cicd/#github-actions","title":"Github Actions","text":"<p>secrets secrets used by Github Actions runner to authenticate to AWS</p> id variable value description 01 AWS_ACCESS_KEY_ID **** AWS admin credential 02 AWS_SECRET_ACCESS_KEY **** AWS admin credential <p>environment variables environment variables used by Github Actions runner</p> id variable value description 01 AWS_REGION ap-southeast-1 AWS region"},{"location":"cicd/#tester","title":"Tester","text":"<p>The tester app uses the test module <code>tester</code> and runs on a dedicated AWS Fargate container</p> <p>docker image</p> <p>environment variables environment variables are passed to the container by Github actions at the <code>run-task</code> cli command</p> id variable description 01 DB_API_URL API endpoint"},{"location":"cicd/#aws-infrastructure","title":"AWS Infrastructure","text":"<p>The AWS infrastructure is organized into layered CloudFormation stacks, segregated by function and coupled through the repository via parameters and configuration files.</p> <p>Cloudformation stacks Cloudformation stack layers</p> id stack purpose resources 01 network initial setup S3 bucket, config and network and VPC for public and private subnets VPC, subnets, security groups, internet gateway 02 database api storage database and connector API DynamoDB tables 03 tester stand-alone tester to validate DB API and other app services Fargate ECS container 04 webscraper serverless Fargate compute resource for Webscraper Fargate compute tasks <p>AWS CLI Additional resources created outside of the cloudformation stack either manually from local PC or via Github actions. </p> <p>These resources must be deleted in a separate cleanup workflow.</p> <p>manual setup resources</p> id resource executor sequence 01 S3 bucket Github Action initial setup 02 S3 config Github Action initial setup after s3 bucket creation 03 ECR Dockerimages Github Action before the stack they are used in"},{"location":"cicd/#github-action-workflows","title":"Github Action Workflows","text":"id workflow app feature description 01 network initial setup and network initial setup, create S3 bucket, global IAM roles, network infrastructure 02 db api database api load database schema, deploy database dynamodb tables and db api stack, upload db api config ex API URL 03 tester tester create docker image for tester Fargate container image, deploy tester stack and upload tester config for SSH access ex tester instance_id 01 webscraper webscraper create docker image"},{"location":"cicd/#setup","title":"Setup","text":"<p>initial setup, create S3 bucket, global IAM roles, network infrastructure</p> id step description 01 create S3 bucket 02 upload global config 03 deploy network stack 04 record, upload deploy artifacts to S3 example: VPC id and endpoints"},{"location":"data_model/","title":"Data model","text":"<p>data model with list of tables and schema information</p> <p>Groups</p> id group description 01 user users and settings 02 search role, role-specific tracks and search profile 03 post job post information with workflow status and details scraped from posts and user-updated 04 crm user specific job application lead conversion model from search results, application, to offer <p>Tables</p> id group table description 01 post post list of registered posts, includes url and workflow status codes 02 post post_details post details either scraped from post or manually updated 03 user user list of users 04 user user_config user profile and customization settings 05 search role generic job roles ex Data Engineer, Data Scientist 06 search track strategic tracks user-role pairs with additional specification for seniority 07 search search_profile search configuration by track: keywords, target salary 08 search job_track job search results for a user search profile, includes track assignment 09 search job derived table from job_track unique list of jobs for single user 10 search track_score match assessment score for a given job-track pair 12 crm track_cv assignment of a user cv to a track 13 crm crm_status job status in the conversion pipeline OPEN, CLOSED, EXPIRED, TOAPPLY, APPLIED, INTERVIEW, etc.. 14 crm apply_status job status in the application workflow OPEN, SUCCESS, FAILED"},{"location":"data_model/#global-patterns","title":"Global patterns","text":"<ul> <li> <p>Primary key Primary key column name <code>id</code> in the origin table and <code>&lt;table_name&gt;_id</code> elsewhere. </p> <ul> <li>Data type Primary key data type String</li> <li>origin single PK for origin, single PK table - auto-incremented Integer</li> <li>assignment combo PK use hash for combo PK <code>&lt;table_A&gt;_&lt;id_A&gt;_&lt;table_B&gt;_&lt;id_B&gt;</code> example <code>post_0002_user_1001</code> for <code>post_id</code>: <code>0002</code> and <code>user_id</code>: <code>1001</code></li> <li>Auto-increment auto-incremented UUID is a running MAX. This is to safely handle deleted records</li> </ul> </li> <li> <p>Date formats limit to two cannonical date formats</p> <ul> <li><code>ISO_TIMESTAMP</code>: YYYY-MM-DD HH:MM:SS</li> <li><code>ISO_DATE</code>: YYYY-MM-DD</li> </ul> </li> <li>SCD columns all tables include <code>created</code> and <code>last_modified</code> timestamp, excluded from this documentation, with <code>ISO_TIMESTAMP</code> format for forward compatibility with SCD update logic</li> </ul>"},{"location":"data_model/#posts","title":"Posts","text":"<p>data tables to describe job post information scraped from the web source ex: MyCareerFutures website or manually entered</p> <p>ERD</p> <pre><code>erDiagram\n    post {\n        String id PK\n        String posted_date\n        String position\n        String company_name\n        String url\n        Number status\n    }\n\n    post_details {\n        String post_id PK, FK\n        String post_source_id FK\n        String closing_date\n        Number salary_high_sgd\n        String url_slug\n        String mcf_ref\n    }\n\n    post_source {\n        String id PK\n        String name\n    }\n\n    post ||--o{ post_details : has\n    post_source ||--o{ post_details : has</code></pre>"},{"location":"data_model/#table-post","title":"Table: post","text":"<ul> <li>Primary Key: <code>id</code> </li> <li>Sort Key: <code>posted_date</code></li> </ul> Column Name Data Type Nullable Description id String No Unique post identifier posted_date String No Date the job was posted position String No Job title status Number No Ingestion stage (e.g., 0=CARD, 1=POST, 2=CLOSED) company_name String Yes Full company name url String Yes URL to the job post"},{"location":"data_model/#table-post_details","title":"Table: post_details","text":"<ul> <li>Primary Key: <code>post_id</code></li> <li>Sort Key: <code>closing_date</code></li> </ul> Column Name Data Type Nullable Description post_id String No Foreign key to post table post_source_id String No Foreign key to post_source table closing_date String No Application deadline date salary_high_sgd Number Yes Maximum salary in SGD url_slug String Yes primary MCF UID reference from url mcf_ref String Yes secondary MCF reference taken from card and or post"},{"location":"data_model/#table-post_source","title":"Table: post_source","text":"<ul> <li>Primary Key: <code>id</code></li> </ul> Column Name Data Type Nullable Description id Number No Unique source identifier name String No ex: MyCareerFutures"},{"location":"data_model/#users","title":"Users","text":"<p>user-related configuration tables</p> <p>ERD</p> <pre><code>erDiagram\n    user {\n        String id PK\n        String email\n        String username\n        String name\n        String deactivated_date\n        Number status\n    }\n\n    user_config {\n        String user_id PK, FK\n        Boolean email_notifications\n    }\n\n    user ||--o{ user_config : has</code></pre>"},{"location":"data_model/#table-user","title":"Table: user","text":"<ul> <li>Primary Key: <code>id</code></li> </ul> Column Name Data Type Nullable Description id String No Unique user identifier email String No Email address username String No Username name String Yes Full name deactivated_date String Yes Account deactivation date status Number No User status (e.g., 1=active)"},{"location":"data_model/#table-user_config","title":"Table: user_config","text":"<ul> <li>Primary Key: <code>user_id</code></li> </ul> Column Name Data Type Nullable Description user_id String No Foreign key to user email_notifications Boolean Yes Whether user receives email notifications"},{"location":"data_model/#search","title":"Search","text":"<p>tables related to user-specific job search </p> <p>ERD</p> <pre><code>erDiagram\n    post {\n        String id PK\n    }\n\n    user {\n        String id PK\n    }\n\n    role {\n        String id PK\n        String role_name\n        String description\n    }\n\n    track {\n        String id PK\n        String user_id FK\n        String role_id FK\n        Number seniority\n    }\n\n    search_profile {\n        String track_id PK, FK\n        String keywords\n        Number salary_target_sgd\n    }\n\n    job_track {\n        String id PK\n        String track_id FK\n        String job_id FK\n        Boolean search_match\n        Boolean assigned\n    }\n\n    job {\n        String id PK\n        String user_id FK\n        String post_id FK\n    }\n\n    job_details {\n        String job_id PK\n        String position\n        String company_name\n    }\n\n    track_score {\n        String job_track_id PK, FK\n        Number score\n        String method\n    }\n\n    user ||--o{ track : has\n    role ||--o{ track : has\n    user ||--o{ job : has\n    post ||--o{ job : has\n    track ||--o{ search_profile : has\n    track ||--o{ job_track : has\n    job ||--o{ job_track : has\n    job_track ||--o{ track_score : has\n    job ||--o{ job_details : has</code></pre>"},{"location":"data_model/#table-role","title":"Table: role","text":"<ul> <li>Primary Key: <code>id</code></li> </ul> Column Name Data Type Nullable Description id String No Role identifier role_name String No Name of the role description String Yes Description of role"},{"location":"data_model/#table-track","title":"Table: track","text":"<ul> <li>Primary Key: <code>id</code></li> <li>Sort Key: <code>user_id</code></li> </ul> Column Name Data Type Nullable Description id String No UUID hash user-role user_id String No Foreign key to user role_id String No Foreign key to role seniority Number Yes Level of seniority (e.g., 1)"},{"location":"data_model/#table-search_profile","title":"Table: search_profile","text":"<ul> <li>Primary Key: <code>track_id</code></li> </ul> Column Name Data Type Nullable Description track_id String No profile ID and foreign key to track keywords String Yes Keywords for job search salary_target_sgd Number Yes Target salary in SGD"},{"location":"data_model/#table-job_track","title":"Table: job_track","text":"<ul> <li>Primary Key: <code>id</code></li> <li>Sort Key: <code>track_id</code></li> </ul> Column Name Data Type Nullable Description id String No UUID hash job-track track_id String No Foreign key to track table job_id String No Foreign key to job table search_match Boolean Yes showed up in search results? [Y/N] assigned Boolean Yes job assigned to the track, only 1 track per job"},{"location":"data_model/#table-job","title":"Table: job","text":"<ul> <li>Primary Key: <code>id</code></li> <li>Sort Key: <code>user_id</code></li> </ul> Column Name Data Type Nullable Description id String No UUID hash user-post user_id String No Foreign key to user table post_id String No Foreign key to post table"},{"location":"data_model/#table-job_details","title":"Table: job_details","text":"<ul> <li>Primary Key: <code>job_id</code></li> </ul> Column Name Data Type Nullable Description job_id String No Foreign key to job table position String Yes manually over-write position company_name String Yes manually over-write company_name"},{"location":"data_model/#table-track_score","title":"Table: track_score","text":"<ul> <li>Primary Key: <code>job_track_id</code></li> </ul> Column Name Data Type Nullable Description job_track_id String No Foreign key to job_track table score Number No 0-1 numeric score of quality of job to track method String No scoring method: keyword, BERT, etc.."},{"location":"data_model/#crm","title":"CRM","text":"<p>User specific job application lead conversion model from search results, application, to offer</p> <p>ERD</p> <pre><code>erDiagram\n    track {\n        String id PK\n        String user_id FK\n        String role_id FK\n    }\n\n    job {\n        String id PK\n    }\n\n    job_track {\n        String id PK\n        String track_id FK\n        String job_id FK\n        Boolean search_match\n        Boolean assigned\n    }\n\n    job_details {\n        String job_id PK\n        String position\n        String company_name\n    }\n\n    track_score {\n        String job_track_id PK, FK\n        Number score\n        String method\n    }\n\n    track_cv {\n        String track_id PK, FK\n        String cv_code\n    }\n\n    crm_status {\n        String job_id PK, FK\n        Number status\n    }\n\n    apply_status {\n        String job_id PK, FK\n        Number status\n    }\n\n    user ||--o{ job : has\n    post ||--o{ job : has\n    user ||--o{ track : has\n    track ||--o{ job_track : has\n    job ||--o{ job_track : has\n    job ||--o{ job_details : has\n    job_track ||--o{ track_score : has\n    track ||--o{ track_cv : has\n    job ||--o{ crm_status : has\n    job ||--o{ apply_status : has</code></pre>"},{"location":"data_model/#table-track_cv","title":"Table: track_cv","text":"<ul> <li>Primary Key: <code>track_id</code></li> </ul> Column Name Data Type Nullable Description track_id String No Foreign key to track table cv_code String No Reference to CV identifier in MCF user profile"},{"location":"data_model/#table-crm_status","title":"Table: crm_status","text":"<ul> <li>Primary Key: <code>job_id</code></li> </ul> Column Name Data Type Nullable Description job_id String No Foreign key to job table status Number No job status in the conversion pipeline OPEN, CLOSED, EXPIRED, TOAPPLY, APPLIED, INTERVIEW, etc.."},{"location":"data_model/#table-apply_status","title":"Table: apply_status","text":"<ul> <li>Primary Key: <code>job_id</code></li> </ul> Column Name Data Type Nullable Description job_id String No Foreign key to job table status Number No job status in the application workflow OPEN, SUCCESS, FAILED"},{"location":"database_api/","title":"Database API","text":"<p>The <code>Database API</code> provides a RESTful interface for CRUD operations on DynamoDB tables defined in the system data model. The API is implemented as a generic Lambda function behind API Gateway, supporting dynamic routing based on path parameters and validating requests using the canonical schema file <code>db_schema.json</code>.</p> <p>This service is designed to act as a thin, schema-aware wrapper over the DynamoDB backend to enable flexible, centralized, and secure access to all operational data in the jobsearch system.</p>"},{"location":"database_api/#design-principles","title":"Design Principles","text":"<ul> <li>Generic Routing: Dynamic table access via path parameters.</li> <li>Schema Enforcement: All incoming payloads are validated against <code>db_schema.json</code>.</li> <li>Minimal Endpoints: A small set of HTTP routes supports all CRUD and batch operations.</li> <li>Modular: Tables can be added/updated without code changes.</li> <li>Internal Use: This API is intended for trusted internal services (e.g., ingestion, screening, CRM).</li> </ul>"},{"location":"database_api/#route-definitions","title":"Route Definitions","text":"<p>Single Record Operations</p> Method Path Description GET <code>/[table]/{id}</code> Fetch item by primary key PUT <code>/[table]/{id}</code> Replace existing item DELETE <code>/[table]/{id}</code> Delete item by primary key <p>Bulk Operations</p> Method Path Description POST <code>/[table]</code> Create a new item POST <code>/[table]/batch</code> Create or update multiple items GET <code>/[table]/search</code> Query items using secondary keys POST <code>/[table]/delete</code> Delete multiple items (by key list)"},{"location":"database_api/#path-parameters","title":"Path Parameters","text":"Param Type Description <code>table</code> string Target table name from schema <code>id</code> string Primary key value"},{"location":"database_api/#body-format","title":"Body Format","text":""},{"location":"database_api/#post-table","title":"POST /[table]","text":"<p>sample body for POST <code>/{job}</code> request</p> <p>request <pre><code>{\n  \"posted_date\": \"2025-08-01\",\n  \"position\": \"Data Engineer\",\n  \"url\": \"https://example.com/jobs/abc123\",\n  ...\n}\n</code></pre></p> <p>response body <pre><code>{\n    \"status\": 1,\n    \"ids\": [\"abc123\"]\n}\n</code></pre></p>"},{"location":"database_api/#post-tablebatch","title":"POST /[table]/batch","text":"<p>sample body for batch POST <code>/{job}/batch</code> request</p> <p>request <pre><code>[\n  {\n      \"posted_date\": \"2025-08-02\",\n      \"position\": \"ML Engineer\",\n      \"load_status\": 0\n  },\n  {\n      \"posted_date\": \"2025-08-05\",\n      \"position\": \"Data Analyst\",\n      \"load_status\": 0\n  }\n]\n</code></pre></p> <p>response body <pre><code>[\n  {\n      \"id\": \"job_0000001\",\n      \"posted_date\": \"2025-08-02\",\n      \"position\": \"ML Engineer\",\n      \"load_status\": 0\n  },\n  {\n      \"id\": \"job_0000002\",\n      \"posted_date\": \"2025-08-05\",\n      \"position\": \"Data Analyst\",\n      \"load_status\": 0\n  }\n]\n</code></pre></p>"},{"location":"enhancements/","title":"Enhancements","text":"<p>Enhancement categories</p> <ul> <li>Cloud and Infrastructure</li> <li>Database and Backend</li> <li>Data Model and ETL</li> <li>Application Logic </li> <li>Match Scoring &amp; Intelligence</li> <li>UI &amp; Front-End</li> </ul>"},{"location":"enhancements/#status","title":"Status","text":"id status enhancement category release 01 open Migrate to AWS using CloudFormation Cloud and Infrastructure 0.1.0 02 open CICD pipeline setup Cloud and Infrastructure 0.1.0 03 backlog Modularize front-end and back-end with API support for agent integration Cloud and Infrastructure 04 backlog Migrate from SQLite to DynamoDB Database and Backend 05 open Implement batching with intermediate DB writes (currently all-or-nothing) Database and Backend 0.1.0 06 backlog Add async support to reduce script latency (cards: 15 min, profiles: 3\u20135 min) Database and Backend 07 backlog Expand data model to include front-end operational tables (currently in Google Sheets) Data Model and ETL 08 backlog Build ETL pipeline to feed into PowerBI dashboard Data Model and ETL 09 backlog Combine cards and profiles components Application Logic 10 backlog Streamline manual lead addition Application Logic 11 backlog Automate track assignment Application Logic 12 backlog Improve SingPass MFA session cookie handling Application Logic 13 backlog Move beyond keyword-only title matching Match Scoring and Intelligence 14 backlog Incorporate job description Match Scoring and Intelligence 15 backlog Use BERT or other ML models Match Scoring and Intelligence 16 backlog Migrate from Google Sheets UI to React.js or Django app UI and Front End 17 backlog Optionally keep GS integration for tabular views UI and Front End"},{"location":"network/","title":"Network","text":"<p>Network access control requirements for AWS-based components in the application architecture. </p> <ul> <li>All public subnets must be associated with an Internet Gateway.</li> <li>VPC endpoints are required for private subnets that need to reach the internet</li> <li>Security groups should be tightly scoped to match access intent (SSH only, HTTP only, etc.).</li> <li>Where possible, use least privilege IAM roles and environment-specific configuration.</li> </ul> <p>Access Groups</p> id access group access control resources 01 global AWS managed IAM credentials S3, Athena, Glue Catalog 02 private subnet VPC + IAM Lambda ETL, DB API, Glue jobs 03 public subnet: outbound only + SSH IAM + SSH key, no inbound HTTP allowed Webscraper, Sheets UI, test EC2 04 public subnet: inbound/outbound HTTP IAM + app-level authentication CRM API (e.g., Flask on EC2/ALB/Fargate)"},{"location":"network/#resources","title":"Resources","text":"<p>network config parameters parameters stored in network config JSON artifact <code>mcfpipe/aws/network/network_config.json</code></p> id resource parameter value description 01 VPC VpcId vpc-*** The VPC every resource should live in. You\u2019ll pass this to anything that needs VPC context (Lambda-in-VPC, ECS/Fargate, RDS, ALB, endpoints). 02 Public Subnet 01 PublicSubnet1Id subnet-**** public subnets: two for different AZs, associated with a route table that has a route to the IGW. Use for internet-facing things or tasks that need a public IP 03 Public Subnet 02 PublicSubnet2Id subnet-**** - same - 04 PrivateSubnetId subnet-**** private subnet: associated with a route table that has a route to the IGW. Use for internet-facing things or tasks that need a public IP 05 security group: Public HTTP SGHTTP sg-**** Inbound: 80/443 from 0.0.0.0/0 06 security group: Private SGPrivate sg-**** private services. Usually no inbound from the internet, only from trusted SGs or within VPC 07 security group: SSH SGSSH sg-**** SSH access to public instances"},{"location":"network/#01-global-aws-managed-services","title":"01. Global AWS Managed Services","text":"<ul> <li>These services are accessed over the public AWS network.</li> <li>No subnet or VPC routing is required.</li> <li>Access is controlled entirely via IAM permissions.</li> </ul> <p>Includes:</p> <ul> <li>S3 (data lake, Parquet storage)</li> <li>Athena (SQL query interface)</li> <li>Glue Catalog (metadata management)</li> </ul>"},{"location":"network/#02-private-subnet-vpc-only","title":"02. Private Subnet (VPC-Only)","text":"<ul> <li>Resources are not publicly accessible.</li> <li>Outbound access is granted via VPC endpoints.</li> <li>Designed for secure backend tasks and services.</li> </ul> <p>Includes:</p> <ul> <li>Lambda ETL functions</li> <li>Glue transformation jobs</li> <li>Internal-facing Database API</li> </ul>"},{"location":"network/#03-public-subnet-outbound-ssh","title":"03. Public Subnet: Outbound + SSH","text":"<ul> <li>Public subnet with internet access for outbound requests.</li> <li>Allows SSH inbound, but blocks HTTP traffic (ports 80/443).</li> <li>Public IPs are assigned automatically (Fargate or EC2).</li> <li>Useful for browser automation, debugging, or interactive tools.</li> </ul> <p>Includes: - Webscraper (e.g., Selenium headless on Fargate) - Google Sheets UI connector - Temporary EC2 debug instances</p>"},{"location":"network/#04-public-subnet-inboundoutbound-http","title":"04. Public Subnet: Inbound/Outbound HTTP","text":"<ul> <li>Public-facing APIs with full internet access.</li> <li>Allows inbound HTTP/S via security group.</li> <li>Should include authentication to protect API endpoints.</li> <li>Can be hosted on EC2, Fargate, or fronted with ALB.</li> </ul> <p>Includes: - CRM API (Flask or Django) - Optional: ALB if scaling to multiple instances</p>"},{"location":"validation/","title":"Validation","text":""},{"location":"validation/#test-cases","title":"Test cases","text":""},{"location":"validation/#database-api","title":"Database API","text":"<p>Pre test setup</p> <ul> <li>load schema and API config </li> </ul> <p>Tests</p> id test type feature to test test method expected outcome 01 positive POST Create new job position=\"Data Engineer\" list of ids with single item 02 positive GET Fetch a single job fetch by id for the job from step 01 job record as json 03 positive PUT Update a single job update the position title to \"Data Engineer contract\" non-empty list of ids 04 positive DELETE Delete a single job delete the job from step 01 status=1 05 positive POST Batch insert new jobs add a batch of jobs including one with posted_date=2025-08-02 return set of ids 06 positive GET Query using secondary keys posted_date=2025-08-02 should return non-empty ids 07 positive DELETE delete a batch of jobs delete batch of jobs by job id status=1 08 negative POST job with missing required field post job with missing field <code>position</code> 400 Bad Request and response text includes \"required\" and \"position\" 10 negative POST job with invalid data type post job with load_status \"zero\" 400 Bad Request and error description includes \"type\", \"integer\"  \"load_status\" 09 negative POST job with invalid date format post job with <code>posted_date</code> = \"May 24, 2025\" 400 Bad Request and error description includes  \"date\", \"format\", \"%Y-%m-%d\" and \"posted_date\" 11 negative GET non-existent job fetch non-existent <code>jobid</code> 404 Not Found and error description includes \"job\", \"not exist\" 12 negative GET non-existent table fetch non-existent <code>table_name</code> 404 Not Found and error description includes \"table\", \"not exist\""},{"location":"workflows/","title":"Workflows","text":"<p>App workflows</p> id workflow description 01 jobs search scrape data from MCF website parse and store into database 02 jobs recommend score and screen jobs for curated report jobs to apply 03 jobs apply apply jobs through MCF website from shortlisted jobs to apply 04 CRM API CRUD operational actions to manage search and move leads through pipeline 05 analytics ETL update parquet DB from data sources DynamoDB tables and refresh BI report 06 config sync update config settings"},{"location":"workflows/#jobs-search","title":"Jobs search","text":"<pre><code>graph TB\n\n%% Config\nDynamoConfig[\"Dynamo: Search config\"]\n\n%% Extraction phase\nCardScraper[\"Fargate: Card Scraper\"]\nS3Cards[\"S3: Card HTML\"]\nCardsQueue[\"SQS: Cards Queue\"]\nParser1[\"Lambda: HTML Parser (cards)\"]\nJobsDB[\"DynamoDB: Jobs\"]\n\nPostScraper[\"Fargate: Post Scraper\"]\nS3Posts[\"S3: Full Post HTML\"]\nPostsQueue[\"SQS: Post Queue\"]\nParser2[\"Lambda: HTML Parser (posts)\"]\n\n%% Transformation + Enrichment\nScorer[\"Lambda: Job Scorer\"]\n\n%% Flow\nDynamoConfig --&gt; CardScraper\nCardScraper --&gt; S3Cards\nCardScraper --&gt; CardsQueue\nCardsQueue --&gt; Parser1\nS3Cards --&gt; Parser1\nParser1 --&gt; CardsQueue\nParser1 --&gt; JobsDB\nCardsQueue --&gt; PostScraper\n\nJobsDB --&gt; PostScraper\nPostScraper --&gt; S3Posts\nPostScraper --&gt; PostsQueue\nPostsQueue --&gt; Parser2\nParser2 --&gt; PostsQueue\nS3Posts --&gt; Parser2\nParser2 --&gt; JobsDB\nPostsQueue --&gt; Scorer\n</code></pre>"},{"location":"workflows/#jobs-recommend","title":"Jobs recommend","text":"<pre><code>graph TB\n\n%% Config\nDynamoConfig[\"Dynamo: Search config\"]\n\n%% Transformation + Enrichment\nJobsDB[\"DynamoDB: Jobs\"]\nPostsQueue[\"SQS: Post Queue\"]\nScorer[\"Lambda: Job Scorer\"]\nScores[\"DynamoDB: Job Scores\"]\n\n%% Decisioning\nScreener[\"Lambda: Screener\"]\nCRM[\"DynamoDB: CRM Data (screened)\"]\n\n%% Flow\nPostsQueue --&gt; Scorer\nDynamoConfig --&gt; Scorer\nJobsDB --&gt; Scorer\nScorer --&gt; Scores\n\nScores --&gt; Screener\nJobsDB --&gt; Screener\nScreener --&gt; CRM\n</code></pre>"},{"location":"workflows/#jobs-apply","title":"Jobs apply","text":"<pre><code>graph TB\n\n%% Cookies\nCredRefresh[\"laptop: login MFA cookie refresh\"]\nCookie[\"DynamoDB: User config (MCF session cookie)\"]\n\n%% Jobs Apply\nUser[\"User\"]\nJobsApply[\"Fargate: MCF jobs apply\"]\nToApply[\"DynamoDB: CRM Data (jobs to apply)\"]\n\n%% Flow\nUser --&gt; CredRefresh\nUser --&gt; JobsApply\nCredRefresh --&gt; Cookie\nCookie --&gt; JobsApply\nToApply --&gt; JobsApply\nJobsApply --&gt; ToApply\n</code></pre>"},{"location":"workflows/#crm-api","title":"CRM API","text":"<pre><code>graph RL\n\nFEApp[\"EC2 Front-end App\"]\nLegacyGSheet[\"Legacy Gsheet UI\"]\nGsheetSync[\"Lambda Gsheet API interface\"]\nCRMAPI[\"CRM API\"]\n\n%% CRM API\nFEApp --&gt; CRMAPI\nCRMAPI --&gt; FEApp \nGsheetSync --&gt; CRMAPI\nGsheetSync --&gt; LegacyGSheet\nLegacyGSheet --&gt; GsheetSync\nCRMAPI --&gt; GsheetSync\n</code></pre>"},{"location":"workflows/#analytics-etl","title":"Analytics ETL","text":"<pre><code>graph TB\n\nDBAPI[\"Database API\"]\nLambdaETL[\"Lambda ETL to Parquet\"]\nDB[\"Parquet DB in S3\"]\nGlue[\"AWS Glue Catalog\"]\nAthena[\"Athena SQL connector\"]\nDF[\"Azure Data Factory\"]\nSSQL[\"Synapse Serverless SQL\"]\nPBI[\"PowerBI\"]\nTBI[\"Tableau\"]\n\n%% ETL flow\nDBAPI --&gt; LambdaETL\nLambdaETL --&gt; DB\nDB --&gt; Glue\nGlue --&gt; Athena\nAthena --&gt; TBI\nDB --&gt; DF\nDF --&gt; SSQL\nSSQL --&gt; PBI\n</code></pre>"},{"location":"releases/010_cloud_infra/","title":"Cloud Infrastructure","text":"<p>This release covers the setup of Cloud infrastructure on AWS for the MCF pipe serverless backend API and database</p>"},{"location":"releases/010_cloud_infra/#situation","title":"Situation","text":"<p>The current version of the app <code>jobsearch</code> runs locally on PC.  Migrating to the cloud improves maintainability and pathway for full automation, with some drawback in development and small cloud operating costs.</p>"},{"location":"releases/010_cloud_infra/#objectives-and-aims","title":"Objectives and aims","text":"<p>Migrate current functionality to AWS Cloud. </p>"},{"location":"releases/010_cloud_infra/#scope","title":"Scope","text":"<p>The current scope includes </p> <ul> <li>Network infrastructure</li> <li>DynamoDB database API</li> <li><code>jobs search</code> workflow</li> </ul> <p>Jobs search Scrape data from MCF website parse and store into cloud AWS DynamoDB database</p>"},{"location":"releases/010_cloud_infra/#system-architecture","title":"System architecture","text":"<p>There are several components of the app, broadly grouped into storage and compute</p> <p>Storage</p> id component description current AWS Infra 01 job posts data jobs and job posts local SQLite database DynamoDB 02 dimension tables config, tracks, keyword libraries GSheet tables DynamoDB 03 CRM data screened, applied, closed, responses, track assignment GSheet tables DynamoDB 04 jobs applied status jobs applied status from MCF apply Gsheet table DynamoDB 05 reports jobs by stage CRM performance analysis Gsheet table SQLite on S3 <p>Compute</p> id component description current AWS Infra 01 Webscraper get MCF search results and job post pages local python scripts Fargate container 02 HTML Parser HTML parse and write to DB local python scripts Lambda + SQS 03 Job Recommender score the posts local python scripts Fargate container 04 GSheet Connector GSheet UI interface local python scripts Lambda 05 MCF Login refresh session cookie manual S3 + Lambda 06 MCF Apply apply jobs local python scripts container Fargate + ECR 07 CRM API write-back, status updates, select jobs to apply, config update GSheet CRM API on EC2 08 Analytics ETL Denormalize from DynamoDB to Parquet GSheet Lambda, Glue, Athena 09 Dashboard Reports and data visualization GSheet PowerBI connect to SQLite on S3 10 DynamoDB API DynamoDB interface API - API Gateway + Lambda 11 Network VPC and network infrastructure - Networking"},{"location":"releases/010_cloud_infra/#app-libraries","title":"App libraries","text":"<p>The source code is modularlized into app libraries since they have unique dependency and environment requirements</p> component requirements resource app library Webscraper selenium, boto3, bs4 Fargate container mcfscrape HTML Parser boto3, bs4 Lambda mcfparse Job Recommender pandas, nltk, scikit-learn, openai Fargate container jobmatch CRM API TBD Flask/Django API Gateway + Lambda jobcrm Analytics ETL pandas, boto3, sqlite3 Lambda jobpipe Gsheet Connector pandas, google api, boto3 Lambda gsheetui Database API boto3 API Gateway + Lambda jobdb"}]}